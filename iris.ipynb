{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Iris Dataset Classification\n",
    "\n",
    "### $\\textbf{Task: Build a logistic regression classifier for sepal petals using the Iris dataset}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Tuple\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "import flax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepallength</th>\n",
       "      <th>sepalwidth</th>\n",
       "      <th>petallength</th>\n",
       "      <th>petalwidth</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sepallength  sepalwidth  petallength  petalwidth        class\n",
       "0          5.1         3.5          1.4         0.2  Iris-setosa\n",
       "1          4.9         3.0          1.4         0.2  Iris-setosa\n",
       "2          4.7         3.2          1.3         0.2  Iris-setosa\n",
       "3          4.6         3.1          1.5         0.2  Iris-setosa\n",
       "4          5.0         3.6          1.4         0.2  Iris-setosa"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"datasets/iris_csv.csv\")\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepallength</th>\n",
       "      <th>sepalwidth</th>\n",
       "      <th>petallength</th>\n",
       "      <th>petalwidth</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>150.000000</td>\n",
       "      <td>150.000000</td>\n",
       "      <td>150.000000</td>\n",
       "      <td>150.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>5.843333</td>\n",
       "      <td>3.054000</td>\n",
       "      <td>3.758667</td>\n",
       "      <td>1.198667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.828066</td>\n",
       "      <td>0.433594</td>\n",
       "      <td>1.764420</td>\n",
       "      <td>0.763161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>4.300000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.100000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>5.100000</td>\n",
       "      <td>2.800000</td>\n",
       "      <td>1.600000</td>\n",
       "      <td>0.300000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>5.800000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>4.350000</td>\n",
       "      <td>1.300000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>6.400000</td>\n",
       "      <td>3.300000</td>\n",
       "      <td>5.100000</td>\n",
       "      <td>1.800000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>7.900000</td>\n",
       "      <td>4.400000</td>\n",
       "      <td>6.900000</td>\n",
       "      <td>2.500000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       sepallength  sepalwidth  petallength  petalwidth\n",
       "count   150.000000  150.000000   150.000000  150.000000\n",
       "mean      5.843333    3.054000     3.758667    1.198667\n",
       "std       0.828066    0.433594     1.764420    0.763161\n",
       "min       4.300000    2.000000     1.000000    0.100000\n",
       "25%       5.100000    2.800000     1.600000    0.300000\n",
       "50%       5.800000    3.000000     4.350000    1.300000\n",
       "75%       6.400000    3.300000     5.100000    1.800000\n",
       "max       7.900000    4.400000     6.900000    2.500000"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.dropna(subset=[\"petallength\", \"petalwidth\", \"sepallength\", \"petalwidth\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Iris-setosa': 0, 'Iris-versicolor': 1, 'Iris-virginica': 2}\n"
     ]
    }
   ],
   "source": [
    "df['class_index'], classes = pd.factorize(df['class'])\n",
    "df = df.drop('class', axis=1)\n",
    "class_map = {class_name: index for (index, class_name) in enumerate(classes)}\n",
    "print(class_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test(df: pd.DataFrame, num_classes, proportion = 0.1) -> Tuple[pd.DataFrame, pd.DataFrame]:\n",
    "    samples = []\n",
    "    for class_index in range(num_classes):\n",
    "        class_df = df[df[\"class_index\"] == class_index]\n",
    "        sample = class_df.sample(n = int(len(class_df) * proportion))\n",
    "        samples.append(sample)\n",
    "    test_df = pd.concat(samples)\n",
    "    train_df = df[~df.index.isin(test_df.index)]\n",
    "    test_df.reset_index(drop=True, inplace=True)\n",
    "    train_df.reset_index(drop=True, inplace=True)\n",
    "    return train_df, test_df\n",
    "\n",
    "train_df, test_df = train_test(df, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set size: 135\n",
      "Test set size: 15\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_df, test_df = train_test_split(df, test_size = 0.1, stratify = df[\"class_index\"])\n",
    "\n",
    "print(f\"Training set size: {len(train_df)}\")\n",
    "print(f\"Test set size: {len(test_df)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model architecture\n",
    "\n",
    "We are going to first just train a linear regression model for logits and then pass that through a softmax function. Our model will take in the $(batch, 4)$ features and pass them through a (4, 3) weight matrix, the outputs will then be softmax'd and we will have our probabilities for each class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.18463236 -0.3223093  -1.022951  ]\n",
      " [ 0.83705264  0.6459639   0.62568444]\n",
      " [ 0.03572375 -0.37918803 -0.25625595]\n",
      " [-1.0434582   0.33855742 -0.15648586]]\n",
      "[-0.7610422  1.3522058 -0.516474 ]\n"
     ]
    }
   ],
   "source": [
    "import flax.linen as nn\n",
    "from jax.nn.initializers import lecun_normal\n",
    "from jax.nn import softmax, one_hot\n",
    "import optax\n",
    "\n",
    "rng_key = jax.random.PRNGKey(42)\n",
    "rng_key, rng_w, rng_b = jax.random.split(rng_key, 3)\n",
    "initializer = jax.nn.initializers.lecun_normal()\n",
    "\n",
    "weights = initializer(rng_w, (4, 3), jnp.float32)\n",
    "bias = initializer(rng_b, (1, 3), jnp.float32)\n",
    "bias = jnp.reshape(bias, (3, ))\n",
    "print(weights)\n",
    "print(bias)\n",
    "\n",
    "def fwd(weights_, bias_, batch_in):\n",
    "    return softmax(batch_in @ weights_ + bias_)\n",
    "\n",
    "def cross_entropy_loss(weights_, bias_, batch_inputs, batch_outputs):\n",
    "    \"\"\"\n",
    "    Batch outputs are one hot encoded vector of true output class\n",
    "    \"\"\"\n",
    "    model_output = fwd(weights_, bias_, batch_inputs)\n",
    "    return -jnp.mean(jnp.sum(batch_outputs * jnp.log(model_output)))\n",
    "\n",
    "optimizer = optax.adam(learning_rate = 0.00001)\n",
    "optimizer_state = optimizer.init((weights, bias))\n",
    "\n",
    "def process_batch(weights, bias, inputs, outputs, optimizer, optimizer_state):\n",
    "    loss, grad = jax.value_and_grad(cross_entropy_loss, argnums=(0, 1))(weights, bias, batch_inputs, batch_outputs)\n",
    "    updates, optimizer_state = optimizer.update(grad, optimizer_state)\n",
    "    (weights, biases) = optax.apply_updates((weights, bias), updates)\n",
    "    return loss, (weights, biases), optimizer_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-9.86907\n",
      "-10.297173\n",
      "-10.773974\n",
      "-9.232189\n",
      "-10.735574\n",
      "-10.526245\n",
      "-10.314912\n",
      "-9.883543\n",
      "-11.274291\n",
      "-11.200541\n",
      "-9.527762\n",
      "-10.671847\n",
      "-9.680386\n",
      "-10.203789\n",
      "-10.515488\n",
      "-10.549166\n",
      "-9.483685\n",
      "-8.82962\n",
      "-10.49518\n",
      "-10.404421\n",
      "-10.017877\n",
      "-10.159428\n",
      "-11.247931\n",
      "-10.854046\n",
      "-10.824501\n",
      "-9.740387\n",
      "-11.676072\n",
      "-10.15776\n",
      "-10.1600485\n",
      "-10.416632\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 300\n",
    "batch_size = 28\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    batch_losses = []\n",
    "    for batch_no in range(len(train_df) // batch_size):\n",
    "        batch_samples = df.sample(batch_size)\n",
    "        batch_inputs  = jnp.array(batch_samples.drop(\"class_index\", axis=1))\n",
    "        batch_outputs = one_hot(batch_samples[\"class_index\"].values, num_classes = 3)\n",
    "        loss, (weights, biases), optimizer_state = process_batch(weights, bias, batch_inputs, batch_outputs, optimizer, optimizer_state)\n",
    "        batch_losses.append(loss)\n",
    "    if ((epoch + 1) % 10 == 0):\n",
    "        print(np.array(batch_losses).mean())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pinn",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
