{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recurrent Neural Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How is an RNN trained, with each token or each sequence?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "\n",
    "import numpy\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "import flax.linen as nn\n",
    "from jax.nn.initializers import lecun_normal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RecurrentLayer(nn.Module):\n",
    "\n",
    "    @nn.compact\n",
    "    def __call__(self, hidden_state, x):\n",
    "        hidden_dim = hidden_state.shape[0]\n",
    "        hidden_transformation = nn.Dense(features=hidden_dim, kernel_init = lecun_normal())(hidden_state)\n",
    "        x_transformation = nn.Dense(features = hidden_dim, kernel_init = lecun_normal())(x)\n",
    "        updated_hidden_state = hidden_state + x\n",
    "        x = nn.tanh(updated_hidden_state)\n",
    "        return updated_hidden_state, x\n",
    "\n",
    "class RNN(nn.Module):\n",
    "    linear_sizes : List[int]\n",
    "\n",
    "    @nn.compact \n",
    "    def __call__(self, hidden_states, x):\n",
    "        updated_hidden_states = []\n",
    "        for hidden_state in hidden_states:\n",
    "            updated_hidden_state, x = RecurrentLayer()(hidden_state, x)\n",
    "            updated_hidden_states.append(updated_hidden_state)\n",
    "\n",
    "        for dim in range(self.linear_sizes[:-1]):\n",
    "            x = nn.Dense(features = dim, kernel_init = lecun_normal())(x)\n",
    "            x = nn.relu(x)\n",
    "        x = nn.Dense(features = self.linear_sizes[:-1], kernel_init=lecun_normal())(x)\n",
    "        x = nn.softmax(x)\n",
    "        \n",
    "        return jnp.array(updated_hidden_states), x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "layers = [128, 128, 3]\n",
    "model = RNN(linear_sizes=layers)\n",
    "rng = jax.random.PRNGKey(42)\n",
    "rng, hidden_init_rng = jax.random.split(rng, 2)\n",
    "hidden_states = lecun_normal()(hidden_init_rng, shape = ((3, 128)), dtype=jnp.float64)\n",
    "\n",
    "batch_in = jnp.ones((10, 10))\n",
    "rng, init_rng = jax.random.split(rng, 2)\n",
    "params = model.init(init_rng, hidden_states, batch_in)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LSTMs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTMCell(nn.Module):\n",
    "\n",
    "    @nn.compact\n",
    "    def __call__(self, hidden_state, long_term_memory, x):\n",
    "        concat = jnp.concatenate([hidden_state, x], axis=1)\n",
    "        forget_gate = nn.sigmoid(nn.Dense(features=long_term_memory.shape[0], kernel_init=lecun_normal())(concat))\n",
    "        intermediate_c = long_term_memory * forget_gate\n",
    "        \n",
    "        input_gate = nn.sigmoid(nn.Dense(features=long_term_memory.shape[0], kernel_init=lecun_normal())(concat))\n",
    "        candidate_gate = nn.tanh(nn.Dense(features=long_term_memory.shape[0], kernel_init=lecun_normal())(concat))\n",
    "        c_t = input_gate * candidate_gate + intermediate_c\n",
    "\n",
    "        # How much of long term memory should be added to hidden state\n",
    "        output_gate = nn.sigmoid(nn.Dense(features=long_term_memory.shape[0], kernel_init=lecun_normal())(concat))\n",
    "        \n",
    "        h_t = nn.tanh(nn.Dense(features=hidden_state.shape[0], kernel_init=lecun_normal())(output_gate * nn.tanh(c_t)))\n",
    "        return h_t, c_t"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
